{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf0e6975",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install faiss.cpu\n",
    "!pip install sentence-transformers\n",
    "!pip install gradio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba04abe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip freeze > requirements.txt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "372dd607",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import faiss\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import ast\n",
    "\n",
    "def load_and_normalize_data(filepath):\n",
    "    df = pd.read_csv(filepath)\n",
    "\n",
    "    # Clean quote and author columns\n",
    "    df['quote'] = df['quote'].astype(str).str.strip().str.lower()\n",
    "    df['author'] = df['author'].astype(str).str.strip().str.lower()\n",
    "\n",
    "   # Function to fix each value in the category column\n",
    "    def clean_category(value):\n",
    "        if isinstance(value, str):\n",
    "            try:\n",
    "                # Try turning the string into a list\n",
    "                result = ast.literal_eval(value)\n",
    "                # If it's already a list, clean each item\n",
    "                if isinstance(result, list):\n",
    "                    return [str(x).strip().lower() for x in result]\n",
    "                # If it's just one word (not a list), make it a list\n",
    "                return [str(result).strip().lower()]\n",
    "            except:\n",
    "                # If it can't be parsed, just clean the text and return in a list\n",
    "                return [value.strip().lower()]\n",
    "        else:\n",
    "            # If it's not a string at all (like None), return empty list\n",
    "            return []\n",
    "\n",
    "    # Apply this cleaning function to every row in the 'category' column\n",
    "    df['category'] = df['category'].apply(clean_category)\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "# -----------------SBERT----------------------------\n",
    "\n",
    "def vectorize_quotes(df):\n",
    "    model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "    embeddings = model.encode(df['quote'].tolist(), convert_to_numpy=True).astype(\"float32\")\n",
    "    return embeddings, model\n",
    "\n",
    "\n",
    "# --------------FAISS-------------------------------\n",
    "\n",
    "def create_faiss_index(embeddings):\n",
    "    index = faiss.IndexFlatL2(embeddings.shape[1])\n",
    "    index.add(embeddings)\n",
    "    return index\n",
    "\n",
    "\n",
    "# ----------------MAIN FUNCTION----------------\n",
    "\n",
    "def main():\n",
    "    dataset_path = \"/content/quotes (1).csv\"\n",
    "    index_path = \"quotes_index.faiss\"\n",
    "\n",
    "    print(\"üì• Loading dataset...\")\n",
    "    df = load_and_normalize_data(dataset_path)\n",
    "\n",
    "    print(\"üß† Creating embeddings with SBERT...\")\n",
    "    embeddings, model = vectorize_quotes(df)\n",
    "\n",
    "    print(\"‚ö° Creating FAISS index...\")\n",
    "    index = create_faiss_index(embeddings)\n",
    "    faiss.write_index(index, index_path)\n",
    "    print(\"‚úÖ FAISS index saved.\")\n",
    "\n",
    "    return df, model, index\n",
    "\n",
    "\n",
    "# ------------ENTRY POINT-----------\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f493bb3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd                       # For handling CSV and data manipulation\n",
    "import faiss                              #  a library developed by Facebook for fast similarity search over vector embeddings.\n",
    "import gradio as gr                       # For creating web-based UI\n",
    "from sentence_transformers import SentenceTransformer  # encode text into vector embeddings for semantic similarity.\n",
    "\n",
    "# ------------------ Load Data and Models ------------------\n",
    "\n",
    "# File paths for the data and FAISS index\n",
    "DATA_PATH = \"/content/quotes (1).csv\"\n",
    "FAISS_INDEX_PATH = \"quotes_index.faiss\"\n",
    "\n",
    "# Load and normalize the quotes dataset\n",
    "df = load_and_normalize_data(DATA_PATH)\n",
    "\n",
    "# Load pre-trained SentenceTransformer model for embedding queries\n",
    "# to convert input queries into semantic vectors.\n",
    "model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "\n",
    "# Load FAISS index for efficient similarity search\n",
    "index = faiss.read_index(FAISS_INDEX_PATH)\n",
    "\n",
    "# ------------------ Quote Search Function ------------------\n",
    "\n",
    "# Function to search for quotes based on user query and optional filters\n",
    "def search_quotes(query, author_filter, category_filter):\n",
    "    results = []  # List to store matching quotes\n",
    "\n",
    "    # Clean and normalize author and category inputs\n",
    "    author = author_filter.strip().lower() if author_filter else None\n",
    "    category = category_filter.strip().lower() if category_filter else None\n",
    "\n",
    "    # Check if the query is empty\n",
    "    if not query:\n",
    "        return \"‚ùå Please enter something to search.\"\n",
    "\n",
    "    # Encode the query into a semantic vector\n",
    "    query_vector = model.encode([query.strip().lower()]).astype(\"float32\") #float32 for FAISS compatibility\n",
    "\n",
    "    # Search the FAISS index for the 20 most similar quote embeddings\n",
    "    distances, indices = index.search(query_vector, 20)\n",
    "\n",
    "    # Loops through the returned indices and fetches the corresponding quotes from the DataFrame\n",
    "    for idx in indices[0]:\n",
    "        row = df.iloc[idx]\n",
    "\n",
    "        # Skip if author doesn't match\n",
    "        if author and row['author'].strip().lower() != author:\n",
    "            continue\n",
    "\n",
    "        # Skip if category doesn't match\n",
    "        if category and category not in [c.strip().lower() for c in row['category']]:\n",
    "            continue\n",
    "\n",
    "        # Format the quote and append to results\n",
    "        quote = f\"‚Äú{row['quote']}‚Äù ‚Äî {row['author'].title()} [üìö {', '.join(row['category'])}]\"\n",
    "        results.append(quote)\n",
    "\n",
    "        # Stop after collecting 5 quotes\n",
    "        if len(results) == 5:\n",
    "            break\n",
    "\n",
    "    # Return results or no match message\n",
    "    return \"\\n\\n\".join(results) if results else \"‚ùå No matching quotes found.\"\n",
    "\n",
    "# ------------------ Random Author Generator ------------------\n",
    "\n",
    "# Function to generate 5 random authors from the dataset\n",
    "def random_authors():\n",
    "    authors = df['author'].dropna().unique().tolist()  # Get unique authors\n",
    "    sample = pd.Series(authors).sample(5).tolist()     # Pick 5 at random\n",
    "    return \", \".join([a.title() for a in sample])      # Format and return\n",
    "\n",
    "# ------------------ Random Category Generator ------------------\n",
    "\n",
    "# Function to generate 5 random categories from the dataset\n",
    "def random_categories():\n",
    "    categories = df['category'].explode().dropna().unique().tolist()  # Flatten list of categories\n",
    "    sample = pd.Series(categories).sample(5).tolist()                 # Pick 5 at random\n",
    "    return \"üìö \" + \" | \".join([c.title() for c in sample])            # Format and return\n",
    "\n",
    "# ------------------ Gradio Interface ------------------\n",
    "\n",
    "# Define the main Gradio Blocks interface\n",
    "with gr.Blocks(title=\"üí¨ Quote Explorer\") as demo:\n",
    "\n",
    "    # üîç Search Quotes Tab\n",
    "    with gr.Tab(\"üîç Search Quotes\"):\n",
    "        gr.Markdown(\"### üîé Find Meaningful Quotes\")  # Description text\n",
    "\n",
    "        # Input fields\n",
    "        query = gr.Textbox(label=\"Search by Meaning\", placeholder=\"e.g. love, courage\")\n",
    "        author = gr.Textbox(label=\"Filter by Author\", placeholder=\"Optional\")\n",
    "        category = gr.Textbox(label=\"Filter by Category\", placeholder=\"Optional\")\n",
    "\n",
    "        # Search button and output textbox\n",
    "        search_btn = gr.Button(\"üîç Search\")\n",
    "        search_output = gr.Textbox(label=\"Results\", lines=8, interactive=False)\n",
    "\n",
    "        # Connect search button to the search_quotes function\n",
    "        search_btn.click(search_quotes, inputs=[query, author, category], outputs=search_output)\n",
    "\n",
    "    # üé≤ Random Authors Tab\n",
    "    with gr.Tab(\"üé≤ Random Authors\"):\n",
    "        gr.Markdown(\"### üé® Discover Random Authors\")\n",
    "\n",
    "        author_btn = gr.Button(\"Show Authors\")                     # Button to show authors\n",
    "        authors_output = gr.Textbox(label=\"Authors\", interactive=False)  # Output box\n",
    "\n",
    "        # Connect button to random author generator\n",
    "        author_btn.click(random_authors, outputs=authors_output)\n",
    "\n",
    "    # üìö Random Categories Tab\n",
    "    with gr.Tab(\"üìö Random Categories\"):\n",
    "        gr.Markdown(\"### üìö Explore Random Quote Categories\")\n",
    "\n",
    "        category_btn = gr.Button(\"Show Categories\")                     # Button to show categories\n",
    "        category_output = gr.Textbox(label=\"Categories\", interactive=False)  # Output box\n",
    "\n",
    "        # Connect button to random category generator\n",
    "        category_btn.click(random_categories, outputs=category_output)\n",
    "\n",
    "    # üí¨ Feedback Tab\n",
    "    with gr.Tab(\"üí¨ Feedback\"):\n",
    "        gr.Markdown(\"### üí¨ Share Your Feedback\")\n",
    "\n",
    "        # Input and output fields for feedback\n",
    "        feedback_input = gr.Textbox(label=\"Your Feedback\", placeholder=\"Write your thoughts here...\", lines=4)\n",
    "        feedback_output = gr.Textbox(label=\"Thanks!\", lines=1, interactive=False)\n",
    "        feedback_btn = gr.Button(\"Submit Feedback\")\n",
    "\n",
    "        # Function to handle feedback submission\n",
    "        def handle_feedback(text):\n",
    "            print(\"üìù Feedback received:\", text)         # Print to console\n",
    "            return \"‚úÖ Thanks for your feedback!\"         # Acknowledge to user\n",
    "\n",
    "        # Connect feedback button to handler\n",
    "        feedback_btn.click(handle_feedback, inputs=feedback_input, outputs=feedback_output)\n",
    "\n",
    "    # ‚ÑπÔ∏è About Tab\n",
    "    with gr.Tab(\"‚ÑπÔ∏è About\"):\n",
    "        gr.Markdown(\"\"\"\n",
    "        ## About Quote Explorer\n",
    "\n",
    "        This application helps you discover inspirational and thought-provoking quotes using semantic search with Sentence Transformers and FAISS indexing.\n",
    "\n",
    "        - Built using Python, Gradio, and SBERT\n",
    "        - Developed by: A ~ I ~ A\n",
    "        - Version: 1.0.0\n",
    "        \"\"\")\n",
    "\n",
    "# ------------------ Launch Gradio App ------------------\n",
    "\n",
    "demo.launch()  # Start the app and open in browser\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
